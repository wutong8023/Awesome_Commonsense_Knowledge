# Commonsense Knowledge Construction and Application Literature 
This repository is maintained by [Tongtong Wu](https://wutong8023.site). Please don't hesitate to send me an email to collaborate or fix some entries (wutong8023 AT gmail.com). 
The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/rgscdxhxbwhp).

This page categorizes the literature by their **Published Venue**..

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#hyperlink)
- [![](https://img.shields.io/badge/ACL-6-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#acl)
- [![](https://img.shields.io/badge/EMNLP-3-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#emnlp)
- [![](https://img.shields.io/badge/NAACL-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#naacl)
- [![](https://img.shields.io/badge/ICLR-2-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#iclr)
- [![](https://img.shields.io/badge/NeurIPS-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#neurips)
- [![](https://img.shields.io/badge/AAAI-7-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#aaai)
- [![](https://img.shields.io/badge/IJCAI-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#ijcai)
- [![](https://img.shields.io/badge/WWW-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#www)
- [![](https://img.shields.io/badge/ESWC-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#eswc)
- [![](https://img.shields.io/badge/SIGDIAL-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#sigdial)
- [![](https://img.shields.io/badge/arXiv-2-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./README.md#arxiv)
## Hyperlink 
- [Homepage](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/README.md)
-  [Summary](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/./)
-  [Application](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/application)
-  [Author](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/author)
-  [Benchmarks](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark)
-  [Knowledge Construction](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/construction)
-  [Contribution](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution)
-  [Data Source](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/data_source)
-  [Published Time](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/time)
-  [Knowledge Utilization](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/utilization)
-  [Published Venue](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/venue)

## ACL

- [![](https://img.shields.io/badge/ACL_Findings-2021-blue)](https://doi.org/10.18653/v1/2021.findings-acl.310)<a href="https://scholar.google.com.hk/scholar?q=It's+All+in+the+Heads:+Using+Attention+Heads+as+a+Baseline+for+Cross-Lingual+Transfer+in+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**It's All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual
Transfer in Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.findings-acl.310) , <br> by *Alexey Tikhonov and
Max Ryabinin* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L520-L533) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```TikhonovR21```
- [![](https://img.shields.io/badge/ACL-2021-blue)](https://doi.org/10.18653/v1/2021.acl-long.102)<a href="https://scholar.google.com.hk/scholar?q=Common+Sense+Beyond+English:+Evaluating+and+Improving+Multilingual+Language+Models+for+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Common Sense Beyond English: Evaluating and Improving Multilingual
Language Models for Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.acl-long.102) , <br> by *Bill Yuchen Lin and
Seyeon Lee and
Xiaoyang Qiao and
Xiang Ren* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L535-L549) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```LinLQ020```
- [![](https://img.shields.io/badge/ACL-2020-blue)](https://doi.org/10.18653/v1/2020.acl-main.515)<a href="https://scholar.google.com.hk/scholar?q=Diverse+and+Informative+Dialogue+Generation+with+Context-Specific+Commonsense+Knowledge+Awareness"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Diverse and Informative Dialogue Generation with Context-Specific
Commonsense Knowledge Awareness**](https://doi.org/10.18653/v1/2020.acl-main.515) , <br> by *Sixing Wu and
Ying Li and
Dawei Zhang and
Yang Zhou and
Zhonghai Wu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L501-L518) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WuLZZW20```
- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1213/)<a href="https://scholar.google.com.hk/scholar?q=Modeling+Naive+Psychology+of+Characters+in+Simple+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Modeling Naive Psychology of Characters in Simple Commonsense Stories**](https://aclanthology.org/P18-1213/) , <br> by *Hannah Rashkin and
Antoine Bosselut and
Maarten Sap and
Kevin Knight and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L220-L237) <br>```Story Commonsense. Story Commonsense [Rashkin et al., 2018a] is a dataset
derived from ROCStories [Mostafazadeh et al., 2016] by annotating the emotions and motivations of the characters. The dataset contains 160,000 examples.
Three classification tasks are involved, namely, the prediction of Maslow’s basic human needs, the prediction of Reiss’ human motives, and the prediction of Plutchik’s eight emotions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```KnightCSRB18```
- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1043/)<a href="https://scholar.google.com.hk/scholar?q=Event2Mind:+Commonsense+Inference+on+Events,+Intents,+and+Reactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Event2Mind: Commonsense Inference on Events, Intents, and Reactions**](https://aclanthology.org/P18-1043/) , <br> by *Hannah Rashkin and
Maarten Sap and
Emily Allaway and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L244-L260) <br>```Event2Mind, Event2Mind contains around 57,000 annotations of intents and reactions for around 25,000 events extracted from various corpora including ROCStories [Mostafazadeh et al., 2016]. Given an event with one or two participants, the system is supposed to predict the intents and reactions of the primary participant, and the reactions of the other participant.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SmithCSRA18```
- [![](https://img.shields.io/badge/ACL-2017-blue)](https://doi.org/10.18653/v1/P17-4020)<a href="https://scholar.google.com.hk/scholar?q=WebChild+2.0+:+Fine-Grained+Commonsense+Knowledge+Distillation"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation**](https://doi.org/10.18653/v1/P17-4020) , <br> by *Niket Tandon and
Gerard de Melo and
Gerhard Weikum* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L84-L97) <br>```WebChild [2014-2017] [2 million concepts, 18 million assertions], is a large-scale commonsense knowledge base that was automatically extracted and disambiguated from Web contents, using semi-supervised label propagation over graphs of noisy candidate assertions. The knowledge base contains triples that connect nouns with adjectives via fine-grained relations like “hasShape”, “hasTaste”, “evokesEmotion”, etc. The arguments of these assertions, nouns and adjectives, are disambiguated by mapping them onto their proper WordNet senses.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```TandonMW17```
## EMNLP

- [![](https://img.shields.io/badge/EMNLP_Findings-2021-blue)](https://doi.org/10.18653/v1/2021.findings-emnlp.349)<a href="https://scholar.google.com.hk/scholar?q=Probing+Commonsense+Explanation+in+Dialogue+Response+Generation"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Probing Commonsense Explanation in Dialogue Response Generation**](https://doi.org/10.18653/v1/2021.findings-emnlp.349) , <br> by *Pei Zhou and
Pegah Jandaghi and
Hyundong Cho and
Bill Yuchen Lin and
Jay Pujara and
Xiang Ren* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L463-L480) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouJCLPR21```
- [![](https://img.shields.io/badge/EMNLP_IJCNLP-2019-blue)](https://doi.org/10.18653/v1/D19-1454)<a href="https://scholar.google.com.hk/scholar?q=Social+IQa:+Commonsense+Reasoning+about+Social+Interactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Social IQa: Commonsense Reasoning about Social Interactions**](https://doi.org/10.18653/v1/D19-1454) , <br> by *Maarten Sap and
Hannah Rashkin and
Derek Chen and
Ronan Le Bras and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L284-L299) <br>```AlphaNLI. Similar to ROCStories, AlphaNLI gives two observations as input, and the system needs to choose the most plausible hypothesized event from two choices, which is supposed to have happened between the two observations. The dataset contains
around 170,000 examples.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SapRCBC19```
- [![](https://img.shields.io/badge/EMNLP-2018-blue)](https://doi.org/10.18653/v1/d18-1009)<a href="https://scholar.google.com.hk/scholar?q=SWAG:+A+Large-Scale+Adversarial+Dataset+for+Grounded+Commonsense+Inference"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense
Inference**](https://doi.org/10.18653/v1/d18-1009) , <br> by *Rowan Zellers and
Yonatan Bisk and
Roy Schwartz and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L264-L279) <br>```SWAG, Situations with Adversarial Generations is a dataset with 113,000 examples, where each example has a beginning sentence followed by four different endings. The system is supposed to choose the most plausible ending from the four choices. The examples of the dataset were filtered adversarially to ensure the problem cannot be solved by simple and
straightforward approaches.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZellersBSC18```
## NAACL

- [![](https://img.shields.io/badge/NAACL-2016-blue)](https://doi.org/10.18653/v1/n16-1098)<a href="https://scholar.google.com.hk/scholar?q=A+Corpus+and+Cloze+Evaluation+for+Deeper+Understanding+of+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense
Stories**](https://doi.org/10.18653/v1/n16-1098) , <br> by *Nasrin Mostafazadeh and
Nathanael Chambers and
Xiaodong He and
Devi Parikh and
Dhruv Batra and
Lucy Vanderwende and
Pushmeet Kohli and
James F. Allen* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L195-L214) <br>```ROCStories. ROCStories  contains 50,000 daily stories consisting of five sentences. During evaluation, a story is given, followed
by two choices, of which one is a plausible ending and the other is an implausible ending. The system needs to choose the correct one from the two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```MostafazadehCHP16```
## ICLR

- [![](https://img.shields.io/badge/ICLR-2020-blue)](https://openreview.net/forum?id=Byg1v1HKDB)<a href="https://scholar.google.com.hk/scholar?q=Abductive+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Abductive Commonsense Reasoning**](https://openreview.net/forum?id=Byg1v1HKDB) , <br> by *Chandra Bhagavatula and
Ronan Le Bras and
Chaitanya Malaviya and
Keisuke Sakaguchi and
Ari Holtzman and
Hannah Rashkin and
Doug Downey and
Wen{-}tau Yih and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L303-L317) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```BhagavatulaBMSH20```
- [![](https://img.shields.io/badge/ICLR-2019-blue)](https://openreview.net/forum?id=rJ4km2R5t7)<a href="https://scholar.google.com.hk/scholar?q=GLUE:+A+Multi-Task+Benchmark+and+Analysis+Platform+for+Natural+Language+Understanding"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural
Language Understanding**](https://openreview.net/forum?id=rJ4km2R5t7) , <br> by *Alex Wang and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L322-L337) <br>```GLUE. The GLUE benchmark is a popular collection of resources for the evaluation of natural language processing systems, which contains multiple tasks that would require systems to have the ability of commonsense reasoning, e.g., natural language inference, textual entailment, and question answering.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WangSMHLB19```
## NeurIPS

- [![](https://img.shields.io/badge/NeurIPS-2019-blue)](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html)<a href="https://scholar.google.com.hk/scholar?q=SuperGLUE:+A+Stickier+Benchmark+for+General-Purpose+Language+Understanding+Systems"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding
Systems**](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html) , <br> by *Alex Wang and
Yada Pruksachatkun and
Nikita Nangia and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L341-L360) <br>```SuperGLUE. The SuperGLUE benchmark improves the GLUE benchmark by incorporating more diﬃcult natural language understanding tasks, to accommodate the increasingly powerful natural language processing systems in recent years.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WangPNSMHLB19```
## AAAI

- [![](https://img.shields.io/badge/AAAI-2021-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/17713)<a href="https://scholar.google.com.hk/scholar?q=CARE:+Commonsense-Aware+Emotional+Response+Generation+with+Latent+Concepts"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**CARE: Commonsense-Aware Emotional Response Generation with Latent
Concepts**](https://ojs.aaai.org/index.php/AAAI/article/view/17713) , <br> by *Peixiang Zhong and
Di Wang and
Pengfei Li and
Chen Zhang and
Hao Wang and
Chunyan Miao* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L444-L461) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhongWLZWM21```
- [![](https://img.shields.io/badge/AAAI-2019-blue)](https://doi.org/10.1609/aaai.v33i01.33013027)<a href="https://scholar.google.com.hk/scholar?q=ATOMIC:+An+Atlas+of+Machine+Commonsense+for+If-Then+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning**](https://doi.org/10.1609/aaai.v33i01.33013027) , <br> by *Maarten Sap and
Ronan Le Bras and
Emily Allaway and
Chandra Bhagavatula and
Nicholas Lourie and
Hannah Rashkin and
Brendan Roof and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L101-L120) <br>```ATOMIC [2019] [309,515 nodes, 877,108 triples], is a commonsense knowledge graph consisting of 877K textual descriptions of inferential knowledge obtained from crowdsourcing. The knowledge graph focuses on if-then relations between events and possible inferences over the events. More specifically, the three types of relation are: “If-Event-Then-Mental-State”, “If-Event-Then-Event”, and “IfEvent-Then-Persona”. The base events were extracted from a variety of corpora
including stories and books.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SapBABLRRSC19```
- [![](https://img.shields.io/badge/AAAI-2018-blue)](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16573)<a href="https://scholar.google.com.hk/scholar?q=Augmenting+End-to-End+Dialogue+Systems+With+Commonsense+Knowledge"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Augmenting End-to-End Dialogue Systems With Commonsense Knowledge**](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16573) , <br> by *Tom Young and
Erik Cambria and
Iti Chaturvedi and
Hao Zhou and
Subham Biswas and
Minlie Huang* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L384-L400) <br>```Retrieval-based Dialogue System.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```YoungCCZBH18```
- [![](https://img.shields.io/badge/AAAI-2018-blue)](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710)<a href="https://scholar.google.com.hk/scholar?q=A+Knowledge-Grounded+Neural+Conversation+Model"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**A Knowledge-Grounded Neural Conversation Model**](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710) , <br> by *Marjan Ghazvininejad and
Chris Brockett and
Ming{-}Wei Chang and
Bill Dolan and
Jianfeng Gao and
Wen{-}tau Yih and
Michel Galley* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L404-L421) <br>```Retrieval-based Dialogue System, 
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```GhazvininejadBC18```
- [![](https://img.shields.io/badge/AAAI-2017-blue)](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972)<a href="https://scholar.google.com.hk/scholar?q=ConceptNet+5.5:+An+Open+Multilingual+Graph+of+General+Knowledge"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ConceptNet 5.5: An Open Multilingual Graph of General Knowledge**](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972) , <br> by *Robyn Speer and
Joshua Chin and
Catherine Havasi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L47-L60) <br>```ConceptNet[1999–2017][8 million nodes 21 million links]. ConceptNet is a semantic network created by the Open Mind Common Sense. It is a directed graph whose nodes are concepts, and the edges represent assertions of commonsense about the concepts, e.g., “is a”, “is used for”, “motivated by goal”, etc. The nodes are natural language phrases, e.g., noun phrases, verb phrases, or clauses. The latest version of the knowledge base is ConceptNet 5.5, which contains over 8 million nodes and over 21 million links.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SpeerCH17```
- [![](https://img.shields.io/badge/AAAI-2016-blue)](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11790)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Interpretation+of+Triangle+Behavior"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Interpretation of Triangle Behavior**](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11790) , <br> by *Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L180-L191) <br>```Triangle-COPA. Triangle-COPA is a variation of COPA with 100 examples in the same format but accompanied with videos. The videos show situations where a circle and a triangle interact with each other. The questions asked are more focused on emotions and intentions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```Gordon16```
- [![](https://img.shields.io/badge/AAAI-2011-blue)](http://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418)<a href="https://scholar.google.com.hk/scholar?q=Choice+of+Plausible+Alternatives:+An+Evaluation+of+Commonsense+Causal+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
Reasoning**](http://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418) , <br> by *Melissa Roemmele and
Cosmin Adrian Bejan and
Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L162-L175) <br>```COPA, The Choice of Plausible Alternatives involves causal inference between events. The dataset contains 1,000 examples in total, and in each example, an event is given, followed by a question asking
for the correct effect or cause from two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```RoemmeleBG11```
## IJCAI

- [![](https://img.shields.io/badge/IJCAI-2018-blue)](https://doi.org/10.24963/ijcai.2018/643)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Knowledge+Aware+Conversation+Generation+with+Graph+Attention"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Knowledge Aware Conversation Generation with Graph Attention**](https://doi.org/10.24963/ijcai.2018/643) , <br> by *Hao Zhou and
Tom Young and
Minlie Huang and
Haizhou Zhao and
Jingfang Xu and
Xiaoyan Zhu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L425-L441) <br>```Template-based Dialogue System, 
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouYHZXZ18```
## WWW

- [![](https://img.shields.io/badge/WWW-2020-blue)](https://doi.org/10.1145/3366423.3380107)<a href="https://scholar.google.com.hk/scholar?q=ASER:+A+Large-scale+Eventuality+Knowledge+Graph"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ASER: A Large-scale Eventuality Knowledge Graph**](https://doi.org/10.1145/3366423.3380107) , <br> by *Hongming Zhang and
Xin Liu and
Haojie Pan and
Yangqiu Song and
Cane Wing{-}Ki Leung* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L124-L140) <br>```ASER [2020] [194,000,677 nodes, 64,351,959 relations],  is a commonsense knowledge
graph consisting of 877K textual descriptions of inferential knowledge obtained from crowdsourcing. The knowledge graph focuses on if-then relations between
events and possible inferences over the events. More specifically, the three types of relation are: “If-Event-Then-Mental-State”, “If-Event-Then-Event”, and “IfEvent-Then-Persona”. The base events were extracted from a variety of corpora including stories and books.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhangLPSL20```
## ESWC

- [![](https://img.shields.io/badge/ESWC-2021-blue)](https://doi.org/10.1007/978-3-030-77385-4\_41)<a href="https://scholar.google.com.hk/scholar?q=CSKG:+The+CommonSense+Knowledge+Graph"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**CSKG: The CommonSense Knowledge Graph**](https://doi.org/10.1007/978-3-030-77385-4\_41) , <br> by *Filip Ilievski and
Pedro A. Szekely and
Bin Zhang* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L145-L159) <br>```CSKG [2021] [2,160,968 nodes, 6,001,531 edges], is a commonsense knowledge base created by consolidating and integrating several other key sources, using the proposed five principles. The resulted knowledge graph contains around 2 million nodes and 6 million edges between them.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```IlievskiSZ21```
## SIGDIAL

- [![](https://img.shields.io/badge/SIGDIAL-2021-blue)](https://aclanthology.org/2021.sigdial-1.13)<a href="https://scholar.google.com.hk/scholar?q=Commonsense-Focused+Dialogues+for+Response+Generation:+An+Empirical+Study"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense-Focused Dialogues for Response Generation: An Empirical
Study**](https://aclanthology.org/2021.sigdial-1.13) , <br> by *Pei Zhou and
Karthik Gopalakrishnan and
Behnam Hedayatnia and
Seokhwan Kim and
Jay Pujara and
Xiang Ren and
Yang Liu and
Dilek Hakkani{-}T{\"{u}}r* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L482-L498) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouGHKPRLH21```
## arXiv

- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://arxiv.org/abs/2201.12438)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Knowledge+Reasoning+and+Generation+with+Pre-trained+Language+Models:+A+Survey"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Knowledge Reasoning and Generation with Pre-trained Language
Models: A Survey**](https://arxiv.org/abs/2201.12438) , <br> by *Prajjwal Bhargava and
Vincent Ng* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L16-L28) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2201-12438```
- [![](https://img.shields.io/badge/CoRR-2021-blue)](https://arxiv.org/abs/2108.04674)<a href="https://scholar.google.com.hk/scholar?q=How+Commonsense+Knowledge+Helps+with+Natural+Language+Tasks:+A+Survey+of+Recent+Resources+and+Methodologies"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**How Commonsense Knowledge Helps with Natural Language Tasks: A Survey
of Recent Resources and Methodologies**](https://arxiv.org/abs/2108.04674) , <br> by *Yubo Xie and
Pearl Pu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L1-L13) <br>```We review some popular commonsense knowledge bases and commonsense reasoning benchmarks, but give more emphasis on the methodologies, and we discuss some future directions in pushing the boundary of commonsense reasoning in natural language processing.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2108-04674```