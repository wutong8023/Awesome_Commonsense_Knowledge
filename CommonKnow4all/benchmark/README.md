# Commonsense Knowledge Base Literature 
This repository is maintained by [Tongtong Wu](). Please don't hesitate to send me an email to collaborate or fix some entries (wutong8023 AT gmail.com). 
The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/rgscdxhxbwhp).

This page categorizes the literature by their **Evaluation Benchmarks of Commonsense Knowledge**.

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#hyperlink)
- [![](https://img.shields.io/badge/Inference_Benchmark_(2_Option)-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#inference-benchmark-(2-option))
- [![](https://img.shields.io/badge/Question_Answering_Benchmark_(2_Option)-2-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#question-answering-benchmark-(2-option))
- [![](https://img.shields.io/badge/Intent_Classification_Benchmark-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#intent-classification-benchmark)
- [![](https://img.shields.io/badge/Motivation_Classification_Benchmark-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#motivation-classification-benchmark)
- [![](https://img.shields.io/badge/Natural_Language_Understanding_Benchmark-2-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#natural-language-understanding-benchmark)
- [![](https://img.shields.io/badge/Emotion_Classification_Benchmark-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#emotion-classification-benchmark)
- [![](https://img.shields.io/badge/Reaction_Classification_Benchmark-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#reaction-classification-benchmark)
- [![](https://img.shields.io/badge/Question_Answering_Benchmark_(3_Option)-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#question-answering-benchmark-(3-option))
- [![](https://img.shields.io/badge/Inference_Benchmark_(4_Option)-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#inference-benchmark-(4-option))
- [![](https://img.shields.io/badge/Human_Needs_Classification_Benchmark-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark/README.md#human-needs-classification-benchmark)
## Hyperlink 
- [Homepage](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/README.md)
-  [Summary](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/./)
-  [Application](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/application)
-  [Author](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/author)
-  [Benchmarks](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark)
-  [Knowledge Construction](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/construction)
-  [Contribution](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution)
-  [Data Source](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/data_source)
-  [Published Time](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/time)
-  [Knowledge Utilization](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/utilization)
-  [Published Venue](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/venue)

## Inference Benchmark (2 Option)

- [![](https://img.shields.io/badge/NAACL-2016-blue)](https://doi.org/10.18653/v1/n16-1098)<a href="https://scholar.google.com.hk/scholar?q=A+Corpus+and+Cloze+Evaluation+for+Deeper+Understanding+of+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense
Stories**](https://doi.org/10.18653/v1/n16-1098) , <br> by *Nasrin Mostafazadeh and
Nathanael Chambers and
Xiaodong He and
Devi Parikh and
Dhruv Batra and
Lucy Vanderwende and
Pushmeet Kohli and
James F. Allen* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L195-L214) <br>```ROCStories. ROCStories  contains 50,000 daily stories consisting of five sentences. During evaluation, a story is given, followed
by two choices, of which one is a plausible ending and the other is an implausible ending. The system needs to choose the correct one from the two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```MostafazadehCHP16```
## Question Answering Benchmark (2 Option)

- [![](https://img.shields.io/badge/AAAI-2016-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/9881)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Interpretation+of+Triangle+Behavior"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Interpretation of Triangle Behavior**](https://ojs.aaai.org/index.php/AAAI/article/view/9881) , <br> by *Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L180-L191) <br>```Triangle-COPA. Triangle-COPA is a variation of COPA with 100 examples in the same format but accompanied with videos. The videos show situations where a circle and a triangle interact with each other. The questions asked are more focused on emotions and intentions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```Gordon16```
- [![](https://img.shields.io/badge/AAAI-2011-blue)](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/viewPaper/2418)<a href="https://scholar.google.com.hk/scholar?q=Choice+of+Plausible+Alternatives:+An+Evaluation+of+Commonsense+Causal+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
Reasoning**](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/viewPaper/2418) , <br> by *Melissa Roemmele and
Cosmin Adrian Bejan and
Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L162-L175) <br>```COPA, The Choice of Plausible Alternatives involves causal inference between events. The dataset contains 1,000 examples in total, and in each example, an event is given, followed by a question asking
for the correct effect or cause from two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```RoemmeleBG11```
## Intent Classification Benchmark

- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1043/)<a href="https://scholar.google.com.hk/scholar?q=Event2Mind:+Commonsense+Inference+on+Events,+Intents,+and+Reactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Event2Mind: Commonsense Inference on Events, Intents, and Reactions**](https://aclanthology.org/P18-1043/) , <br> by *Hannah Rashkin and
Maarten Sap and
Emily Allaway and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L244-L260) <br>```Event2Mind, Event2Mind contains around 57,000 annotations of intents and reactions for around 25,000 events extracted from various corpora including ROCStories [Mostafazadeh et al., 2016]. Given an event with one or two participants, the system is supposed to predict the intents and reactions of the primary participant, and the reactions of the other participant.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SmithCSRA18```
## Motivation Classification Benchmark

- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1213/)<a href="https://scholar.google.com.hk/scholar?q=Modeling+Naive+Psychology+of+Characters+in+Simple+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Modeling Naive Psychology of Characters in Simple Commonsense Stories**](https://aclanthology.org/P18-1213/) , <br> by *Hannah Rashkin and
Antoine Bosselut and
Maarten Sap and
Kevin Knight and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L220-L237) <br>```Story Commonsense. Story Commonsense [Rashkin et al., 2018a] is a dataset
derived from ROCStories [Mostafazadeh et al., 2016] by annotating the emotions and motivations of the characters. The dataset contains 160,000 examples.
Three classification tasks are involved, namely, the prediction of Maslow’s basic human needs, the prediction of Reiss’ human motives, and the prediction of Plutchik’s eight emotions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```KnightCSRB18```
## Natural Language Understanding Benchmark

- [![](https://img.shields.io/badge/NeurIPS-2019-blue)](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html)<a href="https://scholar.google.com.hk/scholar?q=SuperGLUE:+A+Stickier+Benchmark+for+General-Purpose+Language+Understanding+Systems"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding
Systems**](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html) , <br> by *Alex Wang and
Yada Pruksachatkun and
Nikita Nangia and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L341-L360) <br>```SuperGLUE. The SuperGLUE benchmark improves the GLUE benchmark by incorporating more diﬃcult natural language understanding tasks, to accommodate the increasingly powerful natural language processing systems in recent years.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WangPNSMHLB19```
- [![](https://img.shields.io/badge/the_SIGDIAL-2015-blue)](https://doi.org/10.18653/v1/w15-4616)<a href="https://scholar.google.com.hk/scholar?q=Exploiting+knowledge+base+to+generate+responses+for+natural+language+dialog+listening+agents"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Exploiting knowledge base to generate responses for natural language
dialog listening agents**](https://doi.org/10.18653/v1/w15-4616) , <br> by *Sangdo Han and
Jeesoo Bang and
Seonghan Ryu and
Gary Geunbae Lee* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L364-L380) <br>```Template-based Dialogue System,
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```HanBRL15```
## Emotion Classification Benchmark

- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1213/)<a href="https://scholar.google.com.hk/scholar?q=Modeling+Naive+Psychology+of+Characters+in+Simple+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Modeling Naive Psychology of Characters in Simple Commonsense Stories**](https://aclanthology.org/P18-1213/) , <br> by *Hannah Rashkin and
Antoine Bosselut and
Maarten Sap and
Kevin Knight and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L220-L237) <br>```Story Commonsense. Story Commonsense [Rashkin et al., 2018a] is a dataset
derived from ROCStories [Mostafazadeh et al., 2016] by annotating the emotions and motivations of the characters. The dataset contains 160,000 examples.
Three classification tasks are involved, namely, the prediction of Maslow’s basic human needs, the prediction of Reiss’ human motives, and the prediction of Plutchik’s eight emotions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```KnightCSRB18```
## Reaction Classification Benchmark

- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1043/)<a href="https://scholar.google.com.hk/scholar?q=Event2Mind:+Commonsense+Inference+on+Events,+Intents,+and+Reactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Event2Mind: Commonsense Inference on Events, Intents, and Reactions**](https://aclanthology.org/P18-1043/) , <br> by *Hannah Rashkin and
Maarten Sap and
Emily Allaway and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L244-L260) <br>```Event2Mind, Event2Mind contains around 57,000 annotations of intents and reactions for around 25,000 events extracted from various corpora including ROCStories [Mostafazadeh et al., 2016]. Given an event with one or two participants, the system is supposed to predict the intents and reactions of the primary participant, and the reactions of the other participant.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SmithCSRA18```
## Question Answering Benchmark (3 Option)

- [![](https://img.shields.io/badge/EMNLP_IJCNLP-2019-blue)](https://doi.org/10.18653/v1/D19-1454)<a href="https://scholar.google.com.hk/scholar?q=Social+IQa:+Commonsense+Reasoning+about+Social+Interactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Social IQa: Commonsense Reasoning about Social Interactions**](https://doi.org/10.18653/v1/D19-1454) , <br> by *Maarten Sap and
Hannah Rashkin and
Derek Chen and
Ronan Le Bras and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L284-L299) <br>```AlphaNLI. Similar to ROCStories, AlphaNLI gives two observations as input, and the system needs to choose the most plausible hypothesized event from two choices, which is supposed to have happened between the two observations. The dataset contains
around 170,000 examples.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SapRCBC19```
## Inference Benchmark (4 Option)

- [![](https://img.shields.io/badge/EMNLP-2018-blue)](https://doi.org/10.18653/v1/d18-1009)<a href="https://scholar.google.com.hk/scholar?q=SWAG:+A+Large-Scale+Adversarial+Dataset+for+Grounded+Commonsense+Inference"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense
Inference**](https://doi.org/10.18653/v1/d18-1009) , <br> by *Rowan Zellers and
Yonatan Bisk and
Roy Schwartz and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L264-L279) <br>```SWAG, Situations with Adversarial Generations is a dataset with 113,000 examples, where each example has a beginning sentence followed by four different endings. The system is supposed to choose the most plausible ending from the four choices. The examples of the dataset were filtered adversarially to ensure the problem cannot be solved by simple and
straightforward approaches.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZellersBSC18```
## Human Needs Classification Benchmark

- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1213/)<a href="https://scholar.google.com.hk/scholar?q=Modeling+Naive+Psychology+of+Characters+in+Simple+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Modeling Naive Psychology of Characters in Simple Commonsense Stories**](https://aclanthology.org/P18-1213/) , <br> by *Hannah Rashkin and
Antoine Bosselut and
Maarten Sap and
Kevin Knight and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L220-L237) <br>```Story Commonsense. Story Commonsense [Rashkin et al., 2018a] is a dataset
derived from ROCStories [Mostafazadeh et al., 2016] by annotating the emotions and motivations of the characters. The dataset contains 160,000 examples.
Three classification tasks are involved, namely, the prediction of Maslow’s basic human needs, the prediction of Reiss’ human motives, and the prediction of Plutchik’s eight emotions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```KnightCSRB18```