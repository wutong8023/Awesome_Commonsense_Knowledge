# Commonsense Knowledge Base Literature 
This repository is maintained by [Tongtong Wu](). Please don't hesitate to send me an email to collaborate or fix some entries (wutong8023 AT gmail.com). 
The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/rgscdxhxbwhp).

This page categorizes the literature by their **Main Contribution**..

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#hyperlink)
- [![](https://img.shields.io/badge/Survey-2-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#survey)
- [![](https://img.shields.io/badge/New_Knowledge_Base-7-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#new-knowledge-base)
- [![](https://img.shields.io/badge/New_Benchmark-12-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#new-benchmark)
- [![](https://img.shields.io/badge/Empirical_Study-1-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#empirical-study)
- [![](https://img.shields.io/badge/New_Method-8-blue)](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution/README.md#new-method)
## Hyperlink 
- [Homepage](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/README.md)
-  [Summary](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/./)
-  [Application](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/application)
-  [Author](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/author)
-  [Benchmarks](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/benchmark)
-  [Knowledge Construction](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/construction)
-  [Contribution](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/contribution)
-  [Data Source](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/data_source)
-  [Published Time](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/time)
-  [Knowledge Utilization](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/utilization)
-  [Published Venue](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/CommonKnow4all/venue)

## Survey

- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://arxiv.org/abs/2201.12438)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Knowledge+Reasoning+and+Generation+with+Pre-trained+Language+Models:+A+Survey"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Knowledge Reasoning and Generation with Pre-trained Language
Models: A Survey**](https://arxiv.org/abs/2201.12438) , <br> by *Prajjwal Bhargava and
Vincent Ng* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L16-L28) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2201-12438```
- [![](https://img.shields.io/badge/CoRR-2021-blue)](https://arxiv.org/abs/2108.04674)<a href="https://scholar.google.com.hk/scholar?q=How+Commonsense+Knowledge+Helps+with+Natural+Language+Tasks:+A+Survey+of+Recent+Resources+and+Methodologies"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**How Commonsense Knowledge Helps with Natural Language Tasks: A Survey
of Recent Resources and Methodologies**](https://arxiv.org/abs/2108.04674) , <br> by *Yubo Xie and
Pearl Pu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L1-L13) <br>```We review some popular commonsense knowledge bases and commonsense reasoning benchmarks, but give more emphasis on the methodologies, and we discuss some future directions in pushing the boundary of commonsense reasoning in natural language processing.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2108-04674```
## New Knowledge Base

- [![](https://img.shields.io/badge/ESWC-2021-blue)](https://doi.org/10.1007/978-3-030-77385-4\_41)<a href="https://scholar.google.com.hk/scholar?q=CSKG:+The+CommonSense+Knowledge+Graph"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**CSKG: The CommonSense Knowledge Graph**](https://doi.org/10.1007/978-3-030-77385-4\_41) , <br> by *Filip Ilievski and
Pedro A. Szekely and
Bin Zhang* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L144-L157) <br>```CSKG [2021] [2,160,968 nodes, 6,001,531 edges], is a commonsense knowledge base created by consolidating and integrating several other key sources, using the proposed five principles. The resulted knowledge graph contains around 2 million nodes and 6 million edges between them.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```IlievskiSZ21```
- [![](https://img.shields.io/badge/CIKM-2020-blue)](https://doi.org/10.1145/3340531.3412003)<a href="https://scholar.google.com.hk/scholar?q=SenticNet+6:+Ensemble+Application+of+Symbolic+and+Subsymbolic+AI+for+Sentiment+Analysis"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI
for Sentiment Analysis**](https://doi.org/10.1145/3340531.3412003) , <br> by *Erik Cambria and
Yang Li and
Frank Z. Xing and
Soujanya Poria and
Kenneth Kwok* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L65-L81) <br>```SenticNet[2009-2020][200,000 concepts]. Speciﬁcally, semantics deﬁne the denotative information associated with natural language phrases, sentics deﬁne the emotion categorization values, expressed in terms of four aﬀective dimensions associated with these concepts, and polarity is ﬂoating number between −1 and +1. The knowledge base is automatically created from multiple other resources, e.g., WordNet-Affect and OMCS.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```CambriaLXPK20```
- [![](https://img.shields.io/badge/WWW-2020-blue)](https://doi.org/10.1145/3366423.3380107)<a href="https://scholar.google.com.hk/scholar?q=ASER:+A+Large-scale+Eventuality+Knowledge+Graph"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ASER: A Large-scale Eventuality Knowledge Graph**](https://doi.org/10.1145/3366423.3380107) , <br> by *Hongming Zhang and
Xin Liu and
Haojie Pan and
Yangqiu Song and
Cane Wing{-}Ki Leung* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L124-L139) <br>```ASER [2020] [194,000,677 nodes, 64,351,959 relations],  is a commonsense knowledge
graph consisting of 877K textual descriptions of inferential knowledge obtained from crowdsourcing. The knowledge graph focuses on if-then relations between
events and possible inferences over the events. More specifically, the three types of relation are: “If-Event-Then-Mental-State”, “If-Event-Then-Event”, and “IfEvent-Then-Persona”. The base events were extracted from a variety of corpora including stories and books.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhangLPSL20```
- [![](https://img.shields.io/badge/AAAI-2019-blue)](https://doi.org/10.1609/aaai.v33i01.33013027)<a href="https://scholar.google.com.hk/scholar?q=ATOMIC:+An+Atlas+of+Machine+Commonsense+for+If-Then+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning**](https://doi.org/10.1609/aaai.v33i01.33013027) , <br> by *Maarten Sap and
Ronan Le Bras and
Emily Allaway and
Chandra Bhagavatula and
Nicholas Lourie and
Hannah Rashkin and
Brendan Roof and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L101-L120) <br>```ATOMIC [2019] [309,515 nodes, 877,108 triples], is a commonsense knowledge graph consisting of 877K textual descriptions of inferential knowledge obtained from crowdsourcing. The knowledge graph focuses on if-then relations between events and possible inferences over the events. More specifically, the three types of relation are: “If-Event-Then-Mental-State”, “If-Event-Then-Event”, and “IfEvent-Then-Persona”. The base events were extracted from a variety of corpora
including stories and books.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SapBABLRRSC19```
- [![](https://img.shields.io/badge/AAAI-2017-blue)](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14972)<a href="https://scholar.google.com.hk/scholar?q=ConceptNet+5.5:+An+Open+Multilingual+Graph+of+General+Knowledge"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**ConceptNet 5.5: An Open Multilingual Graph of General Knowledge**](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14972) , <br> by *Robyn Speer and
Joshua Chin and
Catherine Havasi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L47-L60) <br>```ConceptNet[1999–2017][8 million nodes 21 million links]. ConceptNet is a semantic network created by the Open Mind Common Sense. It is a directed graph whose nodes are concepts, and the edges represent assertions of commonsense about the concepts, e.g., “is a”, “is used for”, “motivated by goal”, etc. The nodes are natural language phrases, e.g., noun phrases, verb phrases, or clauses. The latest version of the knowledge base is ConceptNet 5.5, which contains over 8 million nodes and over 21 million links.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SpeerCH17```
- [![](https://img.shields.io/badge/ACL-2017-blue)](https://doi.org/10.18653/v1/P17-4020)<a href="https://scholar.google.com.hk/scholar?q=WebChild+2.0+:+Fine-Grained+Commonsense+Knowledge+Distillation"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation**](https://doi.org/10.18653/v1/P17-4020) , <br> by *Niket Tandon and
Gerard de Melo and
Gerhard Weikum* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L84-L97) <br>```WebChild [2014-2017] [2 million concepts, 18 million assertions], is a large-scale commonsense knowledge base that was automatically extracted and disambiguated from Web contents, using semi-supervised label propagation over graphs of noisy candidate assertions. The knowledge base contains triples that connect nouns with adjectives via fine-grained relations like “hasShape”, “hasTaste”, “evokesEmotion”, etc. The arguments of these assertions, nouns and adjectives, are disambiguated by mapping them onto their proper WordNet senses.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```TandonMW17```
- [![](https://img.shields.io/badge/Artificial_Intelligence-1993-blue)](https://www.researchgate.net/profile/John-Sowa-2/publication/220545983_D_B_Lenat_and_R_V_Guha_Building_Large_Knowledge-Based_Systems_Representation_and_Inference_in_the_Cyc_Project/links/54a2cf6d0cf256bf8bb0daf1/D-B-Lenat-and-R-V-Guha-Building-Large-Knowledge-Based-Systems-Representation-and-Inference-in-the-Cyc-Project.pdf)<a href="https://scholar.google.com.hk/scholar?q=Building+large+knowledge-based+systems:+Representation+and+inference+in+the+CYC+project"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Building large knowledge-based systems: Representation and inference in the CYC project**](https://www.researchgate.net/profile/John-Sowa-2/publication/220545983_D_B_Lenat_and_R_V_Guha_Building_Large_Knowledge-Based_Systems_Representation_and_Inference_in_the_Cyc_Project/links/54a2cf6d0cf256bf8bb0daf1/D-B-Lenat-and-R-V-Guha-Building-Large-Knowledge-Based-Systems-Representation-and-Inference-in-the-Cyc-Project.pdf) , <br> by *Lenat, DB and Guha, RV* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L31-L44) <br>```OpenCyc[1984–2012][239,000 concepts 2,039,000 facts]. Concepts in Cyc are called “constants” and categorized into individuals, collections, truth functions, and functions. The Cyc project also includes an inference engine. Currently there are two releases of Cyc. OpenCyc 4.0 is the most recent public version and contains 239,000 concepts and 2,039,000 facts. ResearchCyc is licensed for research purposes and contains 500,000 concepts and 5,000,000 facts.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```lenat1993building```
## New Benchmark

- [![](https://img.shields.io/badge/ACL_Findings-2021-blue)](https://doi.org/10.18653/v1/2021.findings-acl.310)<a href="https://scholar.google.com.hk/scholar?q=It's+All+in+the+Heads:+Using+Attention+Heads+as+a+Baseline+for+Cross-Lingual+Transfer+in+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**It's All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual
Transfer in Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.findings-acl.310) , <br> by *Alexey Tikhonov and
Max Ryabinin* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L526-L540) <br>```XWINO, a multilingual commonsense reasoning benchmark using Winograd Schema Challenge problems. The authors create it by combining several
monolingual collections for six languages, each
described in previously published works.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```TikhonovR21```
- [![](https://img.shields.io/badge/ACL-2021-blue)](https://doi.org/10.18653/v1/2021.acl-long.102)<a href="https://scholar.google.com.hk/scholar?q=Common+Sense+Beyond+English:+Evaluating+and+Improving+Multilingual+Language+Models+for+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Common Sense Beyond English: Evaluating and Improving Multilingual
Language Models for Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.acl-long.102) , <br> by *Bill Yuchen Lin and
Seyeon Lee and
Xiaoyang Qiao and
Xiang Ren* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L545-L559) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```LinLQ020```
- [![](https://img.shields.io/badge/ICLR-2020-blue)](https://openreview.net/forum?id=Byg1v1HKDB)<a href="https://scholar.google.com.hk/scholar?q=Abductive+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Abductive Commonsense Reasoning**](https://openreview.net/forum?id=Byg1v1HKDB) , <br> by *Chandra Bhagavatula and
Ronan Le Bras and
Chaitanya Malaviya and
Keisuke Sakaguchi and
Ari Holtzman and
Hannah Rashkin and
Doug Downey and
Wen{-}tau Yih and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L301-L319) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```BhagavatulaBMSH20```
- [![](https://img.shields.io/badge/EMNLP_IJCNLP-2019-blue)](https://doi.org/10.18653/v1/D19-1454)<a href="https://scholar.google.com.hk/scholar?q=Social+IQa:+Commonsense+Reasoning+about+Social+Interactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Social IQa: Commonsense Reasoning about Social Interactions**](https://doi.org/10.18653/v1/D19-1454) , <br> by *Maarten Sap and
Hannah Rashkin and
Derek Chen and
Ronan Le Bras and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L282-L297) <br>```AlphaNLI. Similar to ROCStories, AlphaNLI gives two observations as input, and the system needs to choose the most plausible hypothesized event from two choices, which is supposed to have happened between the two observations. The dataset contains
around 170,000 examples.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SapRCBC19```
- [![](https://img.shields.io/badge/ICLR-2019-blue)](https://openreview.net/forum?id=rJ4km2R5t7)<a href="https://scholar.google.com.hk/scholar?q=GLUE:+A+Multi-Task+Benchmark+and+Analysis+Platform+for+Natural+Language+Understanding"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural
Language Understanding**](https://openreview.net/forum?id=rJ4km2R5t7) , <br> by *Alex Wang and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L324-L340) <br>```GLUE. The GLUE benchmark is a popular collection of resources for the evaluation of natural language processing systems, which contains multiple tasks that would require systems to have the ability of commonsense reasoning, e.g., natural language inference, textual entailment, and question answering.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WangSMHLB19```
- [![](https://img.shields.io/badge/NeurIPS-2019-blue)](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html)<a href="https://scholar.google.com.hk/scholar?q=SuperGLUE:+A+Stickier+Benchmark+for+General-Purpose+Language+Understanding+Systems"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding
Systems**](https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html) , <br> by *Alex Wang and
Yada Pruksachatkun and
Nikita Nangia and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L344-L363) <br>```SuperGLUE. The SuperGLUE benchmark improves the GLUE benchmark by incorporating more diﬃcult natural language understanding tasks, to accommodate the increasingly powerful natural language processing systems in recent years.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WangPNSMHLB19```
- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1213/)<a href="https://scholar.google.com.hk/scholar?q=Modeling+Naive+Psychology+of+Characters+in+Simple+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Modeling Naive Psychology of Characters in Simple Commonsense Stories**](https://aclanthology.org/P18-1213/) , <br> by *Hannah Rashkin and
Antoine Bosselut and
Maarten Sap and
Kevin Knight and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L218-L235) <br>```Story Commonsense. Story Commonsense [Rashkin et al., 2018a] is a dataset
derived from ROCStories [Mostafazadeh et al., 2016] by annotating the emotions and motivations of the characters. The dataset contains 160,000 examples.
Three classification tasks are involved, namely, the prediction of Maslow’s basic human needs, the prediction of Reiss’ human motives, and the prediction of Plutchik’s eight emotions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```KnightCSRB18```
- [![](https://img.shields.io/badge/ACL-2018-blue)](https://aclanthology.org/P18-1043/)<a href="https://scholar.google.com.hk/scholar?q=Event2Mind:+Commonsense+Inference+on+Events,+Intents,+and+Reactions"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Event2Mind: Commonsense Inference on Events, Intents, and Reactions**](https://aclanthology.org/P18-1043/) , <br> by *Hannah Rashkin and
Maarten Sap and
Emily Allaway and
Noah A. Smith and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L242-L258) <br>```Event2Mind, Event2Mind contains around 57,000 annotations of intents and reactions for around 25,000 events extracted from various corpora including ROCStories [Mostafazadeh et al., 2016]. Given an event with one or two participants, the system is supposed to predict the intents and reactions of the primary participant, and the reactions of the other participant.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```SmithCSRA18```
- [![](https://img.shields.io/badge/EMNLP-2018-blue)](https://doi.org/10.18653/v1/d18-1009)<a href="https://scholar.google.com.hk/scholar?q=SWAG:+A+Large-Scale+Adversarial+Dataset+for+Grounded+Commonsense+Inference"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense
Inference**](https://doi.org/10.18653/v1/d18-1009) , <br> by *Rowan Zellers and
Yonatan Bisk and
Roy Schwartz and
Yejin Choi* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L262-L277) <br>```SWAG, Situations with Adversarial Generations is a dataset with 113,000 examples, where each example has a beginning sentence followed by four different endings. The system is supposed to choose the most plausible ending from the four choices. The examples of the dataset were filtered adversarially to ensure the problem cannot be solved by simple and
straightforward approaches.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZellersBSC18```
- [![](https://img.shields.io/badge/AAAI-2016-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/9881)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Interpretation+of+Triangle+Behavior"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Interpretation of Triangle Behavior**](https://ojs.aaai.org/index.php/AAAI/article/view/9881) , <br> by *Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L178-L189) <br>```Triangle-COPA. Triangle-COPA is a variation of COPA with 100 examples in the same format but accompanied with videos. The videos show situations where a circle and a triangle interact with each other. The questions asked are more focused on emotions and intentions.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```Gordon16```
- [![](https://img.shields.io/badge/NAACL-2016-blue)](https://doi.org/10.18653/v1/n16-1098)<a href="https://scholar.google.com.hk/scholar?q=A+Corpus+and+Cloze+Evaluation+for+Deeper+Understanding+of+Commonsense+Stories"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense
Stories**](https://doi.org/10.18653/v1/n16-1098) , <br> by *Nasrin Mostafazadeh and
Nathanael Chambers and
Xiaodong He and
Devi Parikh and
Dhruv Batra and
Lucy Vanderwende and
Pushmeet Kohli and
James F. Allen* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L193-L212) <br>```ROCStories. ROCStories  contains 50,000 daily stories consisting of five sentences. During evaluation, a story is given, followed
by two choices, of which one is a plausible ending and the other is an implausible ending. The system needs to choose the correct one from the two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```MostafazadehCHP16```
- [![](https://img.shields.io/badge/AAAI-2011-blue)](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/viewPaper/2418)<a href="https://scholar.google.com.hk/scholar?q=Choice+of+Plausible+Alternatives:+An+Evaluation+of+Commonsense+Causal+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
Reasoning**](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/viewPaper/2418) , <br> by *Melissa Roemmele and
Cosmin Adrian Bejan and
Andrew S. Gordon* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L160-L173) <br>```COPA, The Choice of Plausible Alternatives involves causal inference between events. The dataset contains 1,000 examples in total, and in each example, an event is given, followed by a question asking
for the correct effect or cause from two options.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```RoemmeleBG11```
## Empirical Study

- [![](https://img.shields.io/badge/SIGDIAL-2021-blue)](https://aclanthology.org/2021.sigdial-1.13)<a href="https://scholar.google.com.hk/scholar?q=Commonsense-Focused+Dialogues+for+Response+Generation:+An+Empirical+Study"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense-Focused Dialogues for Response Generation: An Empirical
Study**](https://aclanthology.org/2021.sigdial-1.13) , <br> by *Pei Zhou and
Karthik Gopalakrishnan and
Behnam Hedayatnia and
Seokhwan Kim and
Jay Pujara and
Xiang Ren and
Yang Liu and
Dilek Hakkani{-}T{\"{u}}r* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L488-L504) <br></details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouGHKPRLH21```
## New Method

- [![](https://img.shields.io/badge/AAAI-2021-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/17713)<a href="https://scholar.google.com.hk/scholar?q=CARE:+Commonsense-Aware+Emotional+Response+Generation+with+Latent+Concepts"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**CARE: Commonsense-Aware Emotional Response Generation with Latent
Concepts**](https://ojs.aaai.org/index.php/AAAI/article/view/17713) , <br> by *Peixiang Zhong and
Di Wang and
Pengfei Li and
Chen Zhang and
Hao Wang and
Chunyan Miao* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L446-L464) <br>```A Generation-based Dialogue System, which first proposed a framework to learn and construct commonsense-aware emotional latent concepts of the response given an input message and a desired emotion. The authors then proposed three methods to collaboratively incorporate the latent concepts into response generation.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhongWLZWM21```
- [![](https://img.shields.io/badge/EMNLP_Findings-2021-blue)](https://doi.org/10.18653/v1/2021.findings-emnlp.349)<a href="https://scholar.google.com.hk/scholar?q=Probing+Commonsense+Explanation+in+Dialogue+Response+Generation"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Probing Commonsense Explanation in Dialogue Response Generation**](https://doi.org/10.18653/v1/2021.findings-emnlp.349) , <br> by *Pei Zhou and
Pegah Jandaghi and
Hyundong Cho and
Bill Yuchen Lin and
Jay Pujara and
Xiang Ren* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L467-L485) <br>```A Generation-based Dialogue System. 
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouJCLPR21```
- [![](https://img.shields.io/badge/ACL_Findings-2021-blue)](https://doi.org/10.18653/v1/2021.findings-acl.310)<a href="https://scholar.google.com.hk/scholar?q=It's+All+in+the+Heads:+Using+Attention+Heads+as+a+Baseline+for+Cross-Lingual+Transfer+in+Commonsense+Reasoning"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**It's All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual
Transfer in Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.findings-acl.310) , <br> by *Alexey Tikhonov and
Max Ryabinin* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L526-L540) <br>```XWINO, a multilingual commonsense reasoning benchmark using Winograd Schema Challenge problems. The authors create it by combining several
monolingual collections for six languages, each
described in previously published works.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```TikhonovR21```
- [![](https://img.shields.io/badge/ACL-2020-blue)](https://doi.org/10.18653/v1/2020.acl-main.515)<a href="https://scholar.google.com.hk/scholar?q=Diverse+and+Informative+Dialogue+Generation+with+Context-Specific+Commonsense+Knowledge+Awareness"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Diverse and Informative Dialogue Generation with Context-Specific
Commonsense Knowledge Awareness**](https://doi.org/10.18653/v1/2020.acl-main.515) , <br> by *Sixing Wu and
Ying Li and
Dawei Zhang and
Yang Zhou and
Zhonghai Wu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L507-L523) <br>```A Generation-based Dialogue System,  which proposed a felicitous fact recognizer that retrieves knowledge facts from the knowledge base by considering the speciﬁc dialog context.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```WuLZZW20```
- [![](https://img.shields.io/badge/AAAI-2018-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/11923)<a href="https://scholar.google.com.hk/scholar?q=Augmenting+End-to-End+Dialogue+Systems+With+Commonsense+Knowledge"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Augmenting End-to-End Dialogue Systems With Commonsense Knowledge**](https://ojs.aaai.org/index.php/AAAI/article/view/11923) , <br> by *Tom Young and
Erik Cambria and
Iti Chaturvedi and
Hao Zhou and
Subham Biswas and
Minlie Huang* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L386-L402) <br>```A Retrieval-based Dialogue System, incorporated ConceptNet into a retrieval-based chatbot. The model recovers the concepts in the input message using simple n-gram matching, and then encodes the assertions using an LSTM. The assertion with the highest score is then incorporated into the Tri-LSTM to calculate the ﬁnal score of the candidate reply. The model was trained on the Twitter Dialogue Dataset, and compared with several baselines such as supervised word embeddings and memory networks.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```YoungCCZBH18```
- [![](https://img.shields.io/badge/AAAI-2018-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/11977)<a href="https://scholar.google.com.hk/scholar?q=A+Knowledge-Grounded+Neural+Conversation+Model"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**A Knowledge-Grounded Neural Conversation Model**](https://ojs.aaai.org/index.php/AAAI/article/view/11977) , <br> by *Marjan Ghazvininejad and
Chris Brockett and
Ming{-}Wei Chang and
Bill Dolan and
Jianfeng Gao and
Wen{-}tau Yih and
Michel Galley* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L406-L423) <br>```A Generation-based Dialogue System, which generalized the widely used sequence-to-sequence approach by conditioning response generation on both the input conversation history and the external knowledge extracted from the unstructured grounded dataset.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```GhazvininejadBC18```
- [![](https://img.shields.io/badge/IJCAI-2018-blue)](https://doi.org/10.24963/ijcai.2018/643)<a href="https://scholar.google.com.hk/scholar?q=Commonsense+Knowledge+Aware+Conversation+Generation+with+Graph+Attention"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Commonsense Knowledge Aware Conversation Generation with Graph Attention**](https://doi.org/10.24963/ijcai.2018/643) , <br> by *Hao Zhou and
Tom Young and
Minlie Huang and
Haizhou Zhao and
Jingfang Xu and
Xiaoyan Zhu* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L427-L443) <br>```A Template-based Dialogue System, which devised a static graph attention mechanism on the relevant knowledge subgraph retrieved from ConceptNet. The retrieved knowledge graph is used in the knowledge interpreter of the encoder as well as the knowledge aware generator in the decoder.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```ZhouYHZXZ18```
- [![](https://img.shields.io/badge/the_SIGDIAL-2015-blue)](https://doi.org/10.18653/v1/w15-4616)<a href="https://scholar.google.com.hk/scholar?q=Exploiting+knowledge+base+to+generate+responses+for+natural+language+dialog+listening+agents"><img src="https://img.shields.io/badge/-blue.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Exploiting knowledge base to generate responses for natural language
dialog listening agents**](https://doi.org/10.18653/v1/w15-4616) , <br> by *Sangdo Han and
Jeesoo Bang and
Seonghan Ryu and
Gary Geunbae Lee* [[bib]](https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/./bibtex.bib#L367-L382) <br>``` A template-based Dialogue System, wich integrated Freebase into a template-based dialog system that consists of ﬁve modules. Given a user utterance, the system extracts an important name entity from it, and then scans the knowledge base to extract contents related to this entity. The extracted contents are then used to ﬁll in the slots in the response templates.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Commonsense_Knowledge/blob/main/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```HanBRL15```